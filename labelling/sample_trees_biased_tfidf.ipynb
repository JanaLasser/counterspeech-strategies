{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e791908e-3a28-4dbd-b498-a5ed00e7a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3cdeef-71d0-46f0-ac9a-4fd79a22354d",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ab2329-5bd1-47db-8bc2-5c73cd20a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_existing_samples(existing_sample_dir, verbose=False):\n",
    "    existing_sample_files = os.listdir(existing_sample_dir)\n",
    "    existing_sample_files.sort()\n",
    "    existing_sample_counter = int(existing_sample_files[-1].split(\"_\")[1])\n",
    "    existing_samples = pd.DataFrame()\n",
    "    \n",
    "    print(\"loading existing samples\", existing_sample_files)\n",
    "    for f in existing_sample_files:\n",
    "        tmp = pd.read_csv(join(existing_sample_dir, f))\n",
    "        existing_samples = pd.concat([existing_samples, tmp])\n",
    "        \n",
    "    existing_samples['label'] = np.nan\n",
    "    existing_samples.loc[existing_samples['hate_score'] >= 0.8, 'label'] = 'hate'\n",
    "    existing_samples.loc[existing_samples['counter_score'] >= 0.8, 'label'] = 'counter'\n",
    "    existing_samples.loc[(existing_samples['hate_score'] >= 0.44) & \\\n",
    "                         (existing_samples['hate_score'] <= 0.55), 'label'] = 'neutral'\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"existing sample spread to hate / counter / neutral:\")\n",
    "        print(existing_samples['label'].value_counts())\n",
    "        print()\n",
    "        print(\"existing sample spread to the years 2015 / 2016 / 2017 / 2018\")\n",
    "        print(existing_samples[\"year\"].value_counts())\n",
    "        print()\n",
    "\n",
    "    return existing_samples, existing_sample_counter\n",
    "\n",
    "\n",
    "def get_sample_pool(sample_pool_dir):\n",
    "    hate_df = pd.read_csv(join(sample_pool_dir, \"hate.csv\"))\n",
    "    hate_df[\"hate_label\"] = \"hate\"\n",
    "    counter_df = pd.read_csv(join(sample_pool_dir, \"counter.csv\"))\n",
    "    counter_df[\"hate_label\"] = \"counter\"\n",
    "    neutral_df = pd.read_csv(join(sample_pool_dir, \"neutral.csv\"))\n",
    "    neutral_df[\"hate_label\"] = \"neutral\"\n",
    "    \n",
    "    hate_df = hate_df.drop_duplicates(subset=[\"tweet_id\"])\n",
    "    counter_df = counter_df.drop_duplicates(subset=[\"tweet_id\"])\n",
    "    neutral_df = neutral_df.drop_duplicates(subset=[\"tweet_id\"])\n",
    "    \n",
    "    print(f\"sample pool hate: {len(hate_df)}\")\n",
    "    print(f\"sample pool counter: {len(counter_df)}\")\n",
    "    print(f\"sample pool neutral: {len(neutral_df)}\")\n",
    "    print()\n",
    "    \n",
    "    # combine hate, counter and neutral into one pool of available samples\n",
    "    df = pd.concat([hate_df, counter_df, neutral_df])\n",
    "    \n",
    "    print(\"sample pool 2015: {}\".format(len(df[df[\"year\"] == 2015])))\n",
    "    print(\"sample pool 2016: {}\".format(len(df[df[\"year\"] == 2016])))\n",
    "    print(\"sample pool 2017: {}\".format(len(df[df[\"year\"] == 2017])))\n",
    "    print(\"sample pool 2018: {}\".format(len(df[df[\"year\"] == 2018])))\n",
    "    print()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_text(df):\n",
    "    # remove only URLs\n",
    "    df[\"text_clean\"] = df[\"text\"]\\\n",
    "        .apply(lambda x: re.sub(r\"https?:\\/\\/\\S*\", \"\", x, flags=re.MULTILINE))\n",
    "\n",
    "    # lowercase all text\n",
    "    df[\"text_clean\"] = df[\"text\"]\\\n",
    "        .apply(lambda x: x.lower())\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_sample(\n",
    "    df, \n",
    "    year_sample_sizes={2015:125, 2016:125, 2017:125, 2018:125},\n",
    "    years=[2015, 2016, 2017, 2018],\n",
    "    classifier_src=\"../strategy_analysis_roberta\",\n",
    "    classifier_model=\"MultinomialNB\",\n",
    "    embedding=\"TfidfVectorizer\",\n",
    "    ensemble_raters=[\"AS\", \"LT\"],\n",
    "    N=1000,\n",
    "    class_label_dict=None,\n",
    "    class_bias=False,\n",
    "    seed=None):\n",
    "    \n",
    "    classifiers = get_classifiers(\n",
    "        classifier_src, \n",
    "        classifier_model,\n",
    "        embedding,\n",
    "        ensemble_raters,\n",
    "        N\n",
    "    )\n",
    "    \n",
    "    df = ensemble_prediction(df, classifiers, ensemble_raters)\n",
    "    if class_bias:\n",
    "        df[\"pred_label\"] = df[\"pred\"].replace(class_label_dict)\n",
    "        df = df[df[\"pred_label\"] == class_bias]\n",
    "    \n",
    "    frames = []\n",
    "    for year in years:\n",
    "        frames += [\n",
    "            get_tweets_by_year(df, year, \n",
    "                    year_sample_size=year_sample_sizes[year], seed=seed),\n",
    "        ]\n",
    "    \n",
    "    df = pd.concat(frames)\n",
    "    return df\n",
    "\n",
    "\n",
    "def ensemble_prediction(df, classifiers, ensemble_raters):\n",
    "    for rater in ensemble_raters:\n",
    "        X = classifiers[rater][\"embedding\"].transform(df[\"text_clean\"]).toarray()\n",
    "        pred = classifiers[rater][\"classifier\"].predict(X)\n",
    "        df[f\"pred_{rater}\"] = pred\n",
    "\n",
    "    # retain only entries for which all classifiers agree\n",
    "    df = df[df[[f\"pred_{rater}\" for rater in ensemble_raters]]\\\n",
    "                .apply(lambda x: len(set(x.values)) == 1, axis=1)]\n",
    "    df = df.drop(columns=[f\"pred_{rater}\" for rater in ensemble_raters][1:] + [\"text_clean\"])\n",
    "    df = df.rename(columns={f\"pred_{ensemble_raters[0]}\":\"pred\"})  \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_classifiers(src, classifier_model, embedding, ensemble_raters, N):\n",
    "    classifiers = {rater:{} for rater in ensemble_raters}\n",
    "    for rater in ensemble_raters:\n",
    "        tfidf = load(join(src, \"models\", embedding, f\"rater-{rater}_N-{N}.joblib\"))\n",
    "        clf = load(join(src, \"models\", classifier_model, f\"rater-{rater}_N-{N}.joblib\")) \n",
    "        classifiers[rater][\"embedding\"] = tfidf\n",
    "        classifiers[rater][\"classifier\"] = clf\n",
    "        \n",
    "    return classifiers\n",
    "\n",
    "\n",
    "def get_tweets_by_year(df, year, year_sample_size=100, seed=None):\n",
    "    df = df[df.year==year]\n",
    "    sampled_df = df.sample(n=year_sample_size, random_state=seed)\n",
    "    \n",
    "    # in cases where there aren't many tweets for a given year, the desired\n",
    "    # sample size might be larger than the remaining tweets in the sampling pool\n",
    "    assert len(sampled_df) == year_sample_size\n",
    "    \n",
    "    return sampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a228b254-1b81-43cb-98b9-8a3686e1763e",
   "metadata": {},
   "source": [
    "# Build sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82153893-d072-4d22-8d3b-187da4e2bc87",
   "metadata": {},
   "source": [
    "## Sampling principles:\n",
    "* 25% of samples from each of the four years (2015, 2016, 2017, 2018)\n",
    "* combine hate, counter and neutral into a single sample pool\n",
    "* oversample a given class (most likely the minority class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1de88ac6-342a-414d-b355-380ac7737f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_existing_samples = True\n",
    "seed = 42 # note: batch_1_LT_AS.csv was sampled by Joshua without a seed\n",
    "data_dir = \"/home/jana/Projects/CSS_reconquista_internet/analysis/data/\"\n",
    "existing_sample_dir = join(data_dir, \"tree_samples/samples\")\n",
    "sample_pool_dir = join(data_dir, \"tree_samples/data_split_in_classes\")\n",
    "\n",
    "# labels of the condensed classes\n",
    "\n",
    "## setup used for drawing batch 3\n",
    "#condensed_id_to_label = {\n",
    "#    0:\"minority\",\n",
    "#    1:\"opin\",\n",
    "#    2:\"other\",\n",
    "#    3:\"foreign\"\n",
    "#}\n",
    "\n",
    "## setup used for drawing batch 4 & 5\n",
    "condensed_id_to_label = {\n",
    "    0:\"minority\",\n",
    "    1:\"opin\",\n",
    "    2:\"sarc\",\n",
    "    3:\"other\",\n",
    "    4:\"unint\",\n",
    "    5:\"foreign\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "722e9a3e-9c7c-4a93-941f-fa4aadc2c3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing samples ['batch_1_LT_AS.csv', 'batch_2_LT_AS_AH.csv', 'batch_3_AH.csv', 'batch_3_AH_LT.csv', 'batch_3_AS.csv', 'batch_3_AS_AH.csv', 'batch_3_LT.csv', 'batch_3_LT_AH.csv', 'batch_4_AH.csv', 'batch_4_AH_LT.csv', 'batch_4_AS.csv', 'batch_4_AS_AH.csv', 'batch_4_LT.csv', 'batch_4_LT_AH.csv', 'batch_5_AH.csv', 'batch_5_AH_LT.csv', 'batch_5_AS.csv', 'batch_5_AS_AH.csv', 'batch_5_LT.csv', 'batch_5_LT_AH.csv']\n",
      "*** drawing samples for batch 6 for rater AS ***\n",
      "loading existing samples ['batch_1_LT_AS.csv', 'batch_2_LT_AS_AH.csv', 'batch_3_AH.csv', 'batch_3_AH_LT.csv', 'batch_3_AS.csv', 'batch_3_AS_AH.csv', 'batch_3_LT.csv', 'batch_3_LT_AH.csv', 'batch_4_AH.csv', 'batch_4_AH_LT.csv', 'batch_4_AS.csv', 'batch_4_AS_AH.csv', 'batch_4_LT.csv', 'batch_4_LT_AH.csv', 'batch_5_AH.csv', 'batch_5_AH_LT.csv', 'batch_5_AS.csv', 'batch_5_AS_AH.csv', 'batch_5_LT.csv', 'batch_5_LT_AH.csv']\n",
      "existing sample spread to hate / counter / neutral:\n",
      "hate       3589\n",
      "neutral    2029\n",
      "counter    1332\n",
      "Name: label, dtype: int64\n",
      "\n",
      "existing sample spread to the years 2015 / 2016 / 2017 / 2018\n",
      "2018    2276\n",
      "2017    2162\n",
      "2016    1583\n",
      "2015     929\n",
      "Name: year, dtype: int64\n",
      "\n",
      "sample pool hate: 80276\n",
      "sample pool counter: 21865\n",
      "sample pool neutral: 59007\n",
      "\n",
      "sample pool 2015: 2014\n",
      "sample pool 2016: 10597\n",
      "sample pool 2017: 36771\n",
      "sample pool 2018: 108603\n",
      "\n",
      "remaining samples hate: 76994\n",
      "remaining samples counter: 20654\n",
      "remaining samples neutral: 57244\n",
      "\n",
      "remaining samples 2015: 1203\n",
      "remaining samples 2016: 9187\n",
      "remaining samples 2017: 34763\n",
      "remaining samples 2018: 106576\n",
      "\n",
      "\n",
      "****************************\n",
      "\n",
      "*** drawing samples for batch 6 for rater LT ***\n",
      "loading existing samples ['batch_1_LT_AS.csv', 'batch_2_LT_AS_AH.csv', 'batch_3_AH.csv', 'batch_3_AH_LT.csv', 'batch_3_AS.csv', 'batch_3_AS_AH.csv', 'batch_3_LT.csv', 'batch_3_LT_AH.csv', 'batch_4_AH.csv', 'batch_4_AH_LT.csv', 'batch_4_AS.csv', 'batch_4_AS_AH.csv', 'batch_4_LT.csv', 'batch_4_LT_AH.csv', 'batch_5_AH.csv', 'batch_5_AH_LT.csv', 'batch_5_AS.csv', 'batch_5_AS_AH.csv', 'batch_5_LT.csv', 'batch_5_LT_AH.csv', 'batch_6_AS.csv', 'batch_6_AS_AH.csv']\n",
      "existing sample spread to hate / counter / neutral:\n",
      "hate       3938\n",
      "neutral    2186\n",
      "counter    1376\n",
      "Name: label, dtype: int64\n",
      "\n",
      "existing sample spread to the years 2015 / 2016 / 2017 / 2018\n",
      "2018    2501\n",
      "2017    2372\n",
      "2016    1698\n",
      "2015     929\n",
      "Name: year, dtype: int64\n",
      "\n",
      "sample pool hate: 80276\n",
      "sample pool counter: 21865\n",
      "sample pool neutral: 59007\n",
      "\n",
      "sample pool 2015: 2014\n",
      "sample pool 2016: 10597\n",
      "sample pool 2017: 36771\n",
      "sample pool 2018: 108603\n",
      "\n",
      "remaining samples hate: 76675\n",
      "remaining samples counter: 20612\n",
      "remaining samples neutral: 57105\n",
      "\n",
      "remaining samples 2015: 1203\n",
      "remaining samples 2016: 9087\n",
      "remaining samples 2017: 34563\n",
      "remaining samples 2018: 106376\n",
      "\n",
      "\n",
      "****************************\n",
      "\n",
      "*** drawing samples for batch 6 for rater AH ***\n",
      "loading existing samples ['batch_1_LT_AS.csv', 'batch_2_LT_AS_AH.csv', 'batch_3_AH.csv', 'batch_3_AH_LT.csv', 'batch_3_AS.csv', 'batch_3_AS_AH.csv', 'batch_3_LT.csv', 'batch_3_LT_AH.csv', 'batch_4_AH.csv', 'batch_4_AH_LT.csv', 'batch_4_AS.csv', 'batch_4_AS_AH.csv', 'batch_4_LT.csv', 'batch_4_LT_AH.csv', 'batch_5_AH.csv', 'batch_5_AH_LT.csv', 'batch_5_AS.csv', 'batch_5_AS_AH.csv', 'batch_5_LT.csv', 'batch_5_LT_AH.csv', 'batch_6_AS.csv', 'batch_6_AS_AH.csv', 'batch_6_LT.csv', 'batch_6_LT_AH.csv']\n",
      "existing sample spread to hate / counter / neutral:\n",
      "hate       4287\n",
      "neutral    2321\n",
      "counter    1442\n",
      "Name: label, dtype: int64\n",
      "\n",
      "existing sample spread to the years 2015 / 2016 / 2017 / 2018\n",
      "2018    2726\n",
      "2017    2582\n",
      "2016    1813\n",
      "2015     929\n",
      "Name: year, dtype: int64\n",
      "\n",
      "sample pool hate: 80276\n",
      "sample pool counter: 21865\n",
      "sample pool neutral: 59007\n",
      "\n",
      "sample pool 2015: 2014\n",
      "sample pool 2016: 10597\n",
      "sample pool 2017: 36771\n",
      "sample pool 2018: 108603\n",
      "\n",
      "remaining samples hate: 76358\n",
      "remaining samples counter: 20549\n",
      "remaining samples neutral: 56985\n",
      "\n",
      "remaining samples 2015: 1203\n",
      "remaining samples 2016: 8987\n",
      "remaining samples 2017: 34363\n",
      "remaining samples 2018: 106176\n",
      "\n",
      "\n",
      "****************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raters = [\"AS\", \"LT\", \"AH\"]\n",
    "co_raters = {\"AS\":\"AH\", \"LT\":\"AH\", \"AH\":\"LT\"}\n",
    "classifier_src = \"../strategy_analysis/tfidf\"\n",
    "classifier_model = \"LinearSVC\"\n",
    "embedding = \"TfidfVectorizer\"\n",
    "year_sample_sizes = {2015:0, 2016:100, 2017:200, 2018:200}\n",
    "years = [2015, 2016, 2017, 2018]\n",
    "co_rater_frac = 0.1\n",
    "N_labelled_samples = 5500\n",
    "\n",
    "# following the naming convention, the batch counter does not increase for\n",
    "# batches which are only rated by a single rater. I.e. there will be a\n",
    "# batch_3_AS, batch_3_LT and batch_3_AH file for the three raters AS, LT and AH\n",
    "# for the third batch. To ensure this behaviour, we get the batch counter before\n",
    "# we iterate over the raters to create new files.\n",
    "_, existing_sample_counter = get_existing_samples(existing_sample_dir)\n",
    "\n",
    "for rater in raters:\n",
    "    print(f\"*** drawing samples for batch {existing_sample_counter + 1} for rater {rater} ***\")\n",
    "    \n",
    "    # load the existing samples including samples that were created for the\n",
    "    # current batch, but do not increase the batch counter\n",
    "    existing_samples, _ = get_existing_samples(existing_sample_dir, verbose=True)\n",
    "\n",
    "    # load the available pool of examples\n",
    "    sample_pool = get_sample_pool(sample_pool_dir)\n",
    "\n",
    "    # remove the existing samples from the available pool of examples\n",
    "    df = sample_pool[~sample_pool[\"tweet_id\"].isin(existing_samples[\"tweet_id\"])].copy()\n",
    "    print(\"remaining samples hate: {}\".format(len(df[df[\"hate_label\"] == \"hate\"])))\n",
    "    print(\"remaining samples counter: {}\".format(len(df[df[\"hate_label\"] == \"counter\"])))\n",
    "    print(\"remaining samples neutral: {}\".format(len(df[df[\"hate_label\"] == \"neutral\"])))\n",
    "    print()\n",
    "    print(\"remaining samples 2015: {}\".format(len(df[df[\"year\"] == 2015])))\n",
    "    print(\"remaining samples 2016: {}\".format(len(df[df[\"year\"] == 2016])))\n",
    "    print(\"remaining samples 2017: {}\".format(len(df[df[\"year\"] == 2017])))\n",
    "    print(\"remaining samples 2018: {}\".format(len(df[df[\"year\"] == 2018])))\n",
    "    print()\n",
    "    del sample_pool\n",
    "\n",
    "    # clean the text (necessary to embed it)\n",
    "    df = clean_text(df)\n",
    "\n",
    "    sample = create_sample(\n",
    "        df, \n",
    "        year_sample_sizes=year_sample_sizes,\n",
    "        years=years,\n",
    "        classifier_src=classifier_src,\n",
    "        classifier_model=classifier_model,\n",
    "        embedding=embedding,\n",
    "        ensemble_raters=[\"AS\", \"LT\"],\n",
    "        N=N_labelled_samples,\n",
    "        class_label_dict=condensed_id_to_label,\n",
    "        class_bias=\"minority\",\n",
    "        seed=42)\n",
    "    \n",
    "    # replace semicolons with commas, because we use semicolons as delimiters\n",
    "    sample[\"text\"] = sample[\"text\"].apply(lambda x: x.replace(\";\", \",\"))\n",
    "    \n",
    "    # sanity check ensuring that no Tweets in the newly created sample are\n",
    "    # already included in the existing samples\n",
    "    assert len(set(sample[\"tweet_id\"])\\\n",
    "               .intersection(set(existing_samples[\"tweet_id\"]))) == 0\n",
    "    \n",
    "    # sanity check that there are no duplicated tweets in the sample\n",
    "    assert len(sample) == len(sample[\"tweet_id\"].drop_duplicates())\n",
    "    \n",
    "    # save the new sample to disk. The file name encodes the batch number and\n",
    "    # rater\n",
    "    sample_name = f\"batch_{existing_sample_counter + 1}_{rater}.csv\"\n",
    "    sample = sample.drop(columns=[\"pred\", \"hate_label\", \"pred_label\"])\n",
    "    sample.to_csv(join(existing_sample_dir, sample_name), index=False)\n",
    "    \n",
    "    total_sample_size = sum(list(year_sample_sizes.values()))\n",
    "    co_rater_sample_size = int(total_sample_size * co_rater_frac)\n",
    "    co_rater_sample = sample.sample(n=co_rater_sample_size, random_state=seed)\n",
    "    co_rater_sample_name = f\"batch_{existing_sample_counter + 1}_{rater}_{co_raters[rater]}.csv\"\n",
    "    co_rater_sample.to_csv(join(existing_sample_dir, co_rater_sample_name),\n",
    "                           index=False)\n",
    "    \n",
    "    print()\n",
    "    print(\"****************************\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
