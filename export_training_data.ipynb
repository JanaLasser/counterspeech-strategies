{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59406283-1f8a-49a0-a6d7-8bf7398df93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jana/anaconda3/envs/ri/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from germanhass.DBCode.HassDBAdapter import HassDBAdapter\n",
    "from tqdm import tqdm\n",
    "from multiprocess import Pool\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34998aa0-c4e6-4752-98b9-70d9a8af10d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the db\n",
    "db = HassDBAdapter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "365fec37-a5e9-4d1d-8ff3-6f2ab1d1a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information(entry):\n",
    "    row = {\n",
    "        'id':entry['_id'],\n",
    "        'text':' '.join(entry['tokens']),\n",
    "        'label':entry['account_type']\n",
    "    }\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c3c2e0-78b4-42ee-a7e1-7b420ea3a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = '../../data/traindata'\n",
    "number_of_cores = 10\n",
    "pool = Pool(number_of_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f47dd87-9291-4f88-a950-c2c46d3bfcec",
   "metadata": {},
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2d59076-a092-4af2-a697-72045e975419",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hass = list(db.hate_tweets_coll\\\n",
    "    .find({\"test_set\":\"dataset1\"}))\n",
    "train_hass = list(db.hate_tweets_coll\\\n",
    "    .find({\"training_set\":\"dataset1\"}))\n",
    "\n",
    "test_counter = list(db.counter_tweets_coll\\\n",
    "    .find({\"test_set\":\"dataset1\"}))\n",
    "train_counter = list(db.counter_tweets_coll\\\n",
    "    .find({\"training_set\":\"dataset1\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79f42ce0-b68f-4781-ab43-0e06cc2895f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_hass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e864f430-3332-469b-ae64-13c6010557dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 1000000/1000000 [10:47:27<00:00, 25.74it/s]\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "tweets = train_hass + train_counter\n",
    "for row in tqdm(pool.imap_unordered(func=extract_information, \n",
    "                    iterable=tweets), total=len(tweets)):\n",
    "        train = train.append(row, ignore_index=True)\n",
    "#train.to_csv(join(dst, 'train_sample.csv.gzip'), index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "956f6985-a7bb-4951-8330-6ec0a1ccc021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 80000/80000 [06:39<00:00, 200.50it/s]\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "tweets = test_hass[0:-10000] + test_counter[0:-10000]\n",
    "for row in tqdm(pool.imap_unordered(func=extract_information, \n",
    "                    iterable=tweets), total=len(tweets)):\n",
    "        test = test.append(row, ignore_index=True)\n",
    "#test.to_csv(join(dst, 'test_sample.csv.gzip'), index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85b07504-b08b-4d62-a7fa-6b465823fdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 20000/20000 [00:54<00:00, 364.07it/s]\n"
     ]
    }
   ],
   "source": [
    "val = pd.DataFrame()\n",
    "tweets = test_hass[-10000:] + test_counter[-10000:]\n",
    "for row in tqdm(pool.imap_unordered(func=extract_information, \n",
    "                    iterable=tweets), total=len(tweets)):\n",
    "        val = val.append(row, ignore_index=True)\n",
    "#val.to_csv(join(dst, 'val_sample.csv.gzip'), index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2865d3-0fb8-409b-8d74-99f587ab9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, fname in zip([train, test, val], ['train', 'test', 'val']):\n",
    "    df['label'] = df['label'].replace({'counter':0, 'hate':1})\n",
    "    df = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "    df['text'] = df['text'].apply(lambda x: x.replace('\\n', ' '))\n",
    "    np.savetxt(join(dst, '{}_text.txt'.format(fname)), df['text'].values, fmt='%s')\n",
    "    np.savetxt(join(dst, '{}_labels.txt'.format(fname)), df['label'].values, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87826381-0913-4653-84e8-68d4f28c7452",
   "metadata": {},
   "source": [
    "## Dataset DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fcef920-b245-4192-a00b-f17756b2185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hass = list(db.hate_tweets_coll\\\n",
    "    .find({\"test_set\":\"datasetDE\"}))\n",
    "train_hass = list(db.hate_tweets_coll\\\n",
    "    .find({\"training_set\":\"datasetDE\"}))\n",
    "\n",
    "test_counter = list(db.counter_tweets_coll\\\n",
    "    .find({\"test_set\":\"datasetDE\"}))\n",
    "train_counter = list(db.counter_tweets_coll\\\n",
    "    .find({\"training_set\":\"datasetDE\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d7c7a8-2760-477c-b606-38d1b71fd7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [04:42<00:00, 176.75it/s]\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "tweets = train_hass[0:25000] + train_counter[0:25000]\n",
    "for row in tqdm(pool.imap_unordered(func=extract_information, \n",
    "                    iterable=tweets), total=len(tweets)):\n",
    "        train = train.append(row, ignore_index=True)\n",
    "train.to_csv(join(dst, 'dataset_DE_sample_train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a3a81-addf-416f-8612-863fed3b5791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████████████████████████████████████                                                                                                  | 391895/1000000 [2:28:27<5:30:56, 30.63it/s]"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "tweets = train_hass + train_counter\n",
    "for row in tqdm(pool.imap_unordered(func=extract_information, \n",
    "                    iterable=tweets), total=len(tweets)):\n",
    "        train = train.append(row, ignore_index=True)\n",
    "train.to_csv(join(dst, 'dataset_DE_train.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
